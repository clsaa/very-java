# 5.Java内存模型与线程

## 5.1.硬件效率与一致性

“让计算机并发执行若千个运算任务”与“更充分地利用计算机处理器的效能”之间的因果关系，看起来顺理成章，实际上它们之间的关系并没有想象中的那么简单，其中-一个重要的复杂性来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作是很难消除的(无法仅靠寄存器来完成所有运算任务）。由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加人一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。

基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引人了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），如图 12-1 所示。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决-致性的问题，需要各个处理器访问缓存时都遵循--些协议，在读写时要根据协议来进行操作，这类协议有 MSI、MESI  (llinois Protocol）、MOSI、Synapse、Firefly 及 Dragon Protocol 等。在本章中将会多次提到的“内存模型”一词，可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机器可以拥有不一样的内存模型，而 Java 虚拟机也有自己的内存模型，并且这里介绍的内存访问操作与硬件的缓存访问操作具有很高的可比性。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-014122.png)

除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Ou-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一- 致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序-致，因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java 虚拟机的即时编译器中也有类似的指令重排序（InstructionReorder）优化。

## 5.2.Java内存模型

Java 虚拟机规范中试图定义一种 Java 内存模型（JavaMemoryModel, JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的 内存访问效果。在此之前，主流程序语言(如C/C++等)直接使用物理硬件和操作系统的内存模型，因此，会由于不同平台，上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外-套平台上并发访问却经常出错，因此在某些场景就必须针对不同的平台来编写程序。

定义 Java 内存模型并非一件容易的事情，这个模型必须定义得足够严谨，才能让 Java 的并发内存访问操作不会产生歧义；但是，也必须定义得足够宽松，使得虚拟机的实现有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存和指令集中某些特有的指令）来获取更好的执行速度。经过长时间的验证和修补，在 JDK 1.5（实现了 JSR-1339) 发布后，Java 内存模型已经成熟和完善起来了。


## 5.2.1.主内存与工作内存

Java 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量（Variables）与 Java 编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。为了获得较好的执行效能，Java 内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。

Java 内存模型规定了所有的变量都存储在主内存（MainMemory）中（此处的主内存与介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部分）。每条线程还有自己的工作内存（WorkingMemory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝。**线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图所示。**

**如果局部变量是一个 reference 类型，它引用的对象在 Java 堆中可被各个线程共享，但是 reference 本身在 Java 栈的局部变量表中，它是线程私有的。**

**“拷贝副本”提出疑问，如“假设线程中访问-一个 10 MB 的对象，也会把这 10 MB 的内存复制一份拷贝出来吗？”，事实上并不会如此，这个对象的引用、对象中某个在线程访问到的字段是有可能存在拷贝的，但不会有虚拟机实现成把整个对象拷贝一次。**

**根据 Java 虚拟机规范的规定，volatile 变量依然有工作内存的拷贝，但是由于它特殊的操作顺序性规定（后文会讲到），所以看起来如同直接在主内存中读写访问一般，因此这里的描述对于 volatile 也并不存在例外。**

**这里所讲的主内存、工作内存与前面所讲的 Java 内存区域中的 Java 堆、栈、方法区等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于 Java 堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。从更低层次上说，主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机（甚至是硬件系统本身的优化措施）可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是工作内存。**

### 5.2.2.内存间交互操作

关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，**Java 内存模型中定义了以下 8 种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的**（对于 double 和 long 类型的变量来说，load、store、read 和 write 操作在某些平台上允许有例外）

* lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。
* unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
* read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用。
* load（载入）：作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。
* use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。
* assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
* store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write 操作使用。
* write（写入）：作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中。

**如果要把一个变量从主内存复制到工作内存，那就要顺序地执行 read 和 load 操作，如果要把变量从工作内存同步回主内存，就要顺序地执行 store 和 write 操作。注意，Java 内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read 与 load 之间、store 与 write 之间是可插入其他指令的，如对主内存中的变量 a、b 进行访问时，一种可能出现顺序是 read a、read b、load b、load a。**除此之外，Java 内存模型还规定了在执行上述 8 种基本操作时必须满足如下规则：

这 8 种内存访问操作以及上述规则限定，再加上稍后介绍的对 volatile I 的一些特殊规定，就已经完全确定了 Java 程序中哪些内存访问操作在并发下是安全的。由于这种定义相当严谨但又十分烦琐，实践起来很麻烦，稍后介绍这种定义的一个等效判断原则一一先行发生原则，用来确定一个访问在并发环境下是否安全。

### 5.2.3.Volatile变量的特殊规则

关键字 volatile 可以说是 Java 虚拟机提供的最轻量级的同步机制，但是它并不容易完全被正确、完整地理解，以至于许多程序员都习惯不去使用它，遇到需要处理多线程数据竞争问题的时候一律使用 synchronized 来进行同步。了解 volatile 变量的语义对后面了解多线程操作的其他特性很有意义，在本节中我们将多花费一些时间去弄清楚 volatile 的语义到底是什么。

**当一个变量定义为 volatile 之后，它将具备两种特性，第一是保证此变量对所有线程的可呢性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通変量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成，例如，线程 A 修改一个普通变量的值，然后向主内存进行回写，另外一条线程 B 在线程 A 回写完成了之后再从主内存进行读取操作，新变量值才会对线程 B 可见。**

关于 volatile 变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile 变量对所有线程是立即可见的，对 volatile 变量所有的写操作都能立刻反应到其他线程之中，换句话说，volatile 变量在各个线程中是一致的，所以基于 volatile 变量的运算在并发下是安全的”。这句话的论据部分并没有错，但是其论据并不能得出“基于 volatile 变量的运算在并发下是安全的”这个结论。**volatile 变量在各个线程的工作内存中不存在一致性问题（在各个线程的工作内存中，volatile 变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引整看不到不一致的情况，因此可以认为不存在一致性间题），但是 Java 里面的运算并非原子操作，导致 volatile 变量的运算在并发下一样是不安全的，**我们可以通过一段简单的演示来诡明原因，请看代码清单A中演示的例子。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-030459.png)

这段代码发起了 20 个线程，每个线程对 race 变量进行 10600 次自增操作，如果这段代码能够正确并发的话，最后输出的结果应该是 200000。读者运行完这段代码之后，并不会获得期望的结果，而且会发现每次运行程序，输出的结果都不一样，都是一个小于 200000 的数字，这是为什么呢？

问题就出现在自增运算“race남“”之中，我们用 Javap 反编译这段代码后会得到代码清单发现只有一行代码的 increase（）方法在 Class 文件中是由 4 条字节码指令构成的（return 指令不是由 race++产生的，这条指令可以不计算），从字节码层面上很容易就分析出并发失败的原因了：当 getstatic 指令把 race 的值取到操作栈顶时，volatile 关键字保证了 race 的值在此时是正确的，但是在执行 const_1、iadd 这些指令的时候，其他线程可能已经把 race的值加大了，而在操作栈顶的值就变成了过期的数据，所以 putstatic 指令执行后就可能把较小的 race 值同步回主内存之中。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-030804.png)

客观地说，笔者在此使用字节码来分析并发问题，仍然是不严谨的，因为即使编译出来只有一条字节码指令，也并不意味执行这条指令就是-个原子操作。一条字节码指令在解释执行时，解释器将要运行许多行代码才能实现它的语义，如果是编译执行，一条字节码指令也可能转化成若千条本地机器码指令，此处使用-XX: +PrintAssembly 参数输出反汇编来分析会更加严谨一些，但考虑到读者阅读的方便，并且字节码已经能说明问题，所以此处使用字节码来分析。

由于 volatile 变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁（使用 synchronized 或 java. Util. Concurrent 中的原子类）来保证原子性。

* 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值
* 变量不需要与其他的状态变量共同参与不变约束

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-051534.png)
![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-051542.png)

使用 volatile 变量的第二个语义是禁止指令重排序优化，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这也就是 Java 内存模型中描述的所谓的“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。

上面的描述仍然不太容易理解，我们还是继续通过一个例子来看看为何指令重排序会干扰程序的并发执行，演示程序如代码清单所示。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-051804.png)

代码清单 12-4 中的程序是一段伪代码，其中描述的场景十分常见，只是我们在处理配置文件时一般不会出现并发而已。如果定义 initialized 变量时没有使用 volatile 修饰，就可能会由于指令重排序的优化，导致位于线程 A 中最后一句的代码“initialized-true'，被提前执行（这里虽然使用 Java 作为伪代码，但所指的重排序优化是机器级的优化操作，提前执行是指这句话对应的汇编代码被提前执行），这样在线程 B 中使用配置信息的代码就可能出现错误，而 volatile 关键字则可以避免此类情况的发生.指令重排序是并发编程中最容易让开发人员产生疑惑的地方，除了上面伪代码的例子之外，笔者再举一个可以实际操作运行的例子来外析 volatile 关键字是如何禁止指令重排序优化的。代码清单是一段标准的 DCL 单例代码，可以观察加入 volatile 和未加入 volatile 关键字时所生成汇编代码的差别

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-055850.png)

**Volatile 屏蔽指令重排序的语义在 JDK1.5 中才被完全修复，此前的 JDK 中即使将变量声明为 volatile 也仍然不能完全避免重排序所导致的问题（主要是 volatile 变量前后的代码仍然存在重排序问题），这点也是在 JDK 1.5 之前的 Java 中无法安全地使用 DCL（双锁检测）来实现单例模式的原因。**

**通过对比就会发现，关键变化在于有 volatile 修饰的变量，赋值后（前面 mov%eax,)“操作，这个操 0 x150 (%esi）这句便是赋值操作）多执行了一个“lockaddl$0 x0, (%esp作相当于一个内存屏障（MemoryBarrier 或 MemoryFence，指重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个 CPU 访问内存时，并不需要内存屏障；但如果有两个或更多 CPU 访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证- 致性了。这句指令中的“addl$0 x0, (%esp) "（把 ESP 寄存器的值加 0) 显然是一个空操作指令（采用这个空操作而不是空操作指令 nop 是因为 IA32 手册规定 lock 前缀不允许配合 nop 使用），关键在于 lock 前缀，查询 1 A32 手册，它的作用是使得本 CPU 的 Cache 写入了内存。该写入动作也会引起别的 CPU 或者别的内核无效化（Invalidate）其 Cache，这种操作相当于对 Cache 中的变量做了一次前面介绍 Java 内存模式中所说的“store 和 write“操作，所以通过这样一个空操作，可让前面 volatile 变量的修改对其他 CPU 立即可见。**

那为何说它禁止指令重排序呢？**从硬件架构上讲，指令重排序是指 CPU 采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理。但并不是说指令任意重排，CPU 需要能正确处理指令依赖情况以保障程序能得出正确的执行结果。譬如指令 1 把地址 A 中的值加 10, 指令 2 把地址中的值乘以 2, 指令 3 把地址 B 中的值减去 3, 这时指令 1 和指令 2 是有依赖的，它们之间的顺序不能重排一一（A+10) *2 与 A*2+10 显然不相等，但指令 3 可以重排到指令 1、2 之前或者中间，只要保证 CPU 执行后面依赖到 A、B 值的操作时能获取到正确的 A 和值即可。所以在本内 CPU 中，重排序看起来依然是有序的。因此，lockaddl$0 x0, (%esp）指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，这样便形成了“指令重排序无法越过内存屏障”的效果**

解决了 volatile 的语义问题，再来看看在众多保障并发安全的工具中选用 volatile 的意义-它能让我们的代码比使用其他的同步工具更快吗？在某些情况下，volatile 的同步机制的性能确实要优于锁（使用 synchronized 关键字或 java. Util. Concurrent 包里面的锁），但是由于虚拟机对锁实行的许多消除和优化，使得我们很难量化地认为 volatile 就会比 synchronized 快多少。如果让 volatile 自己与自己比较，那可以确定一个原则：volatile 变量读操作的性能消耗与普通变量几乎没有什么差别，但是写操作则可能会慢一些，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。不过即便如此，大多数场景下 volatile 的总开销仍然要比锁低，我们在 volatile 与锁之中选择的唯一依据仅仅是Volatile 的语义能否满足使用场景的需求。

在本节的最后，我们回头看一下 Java 内存模型中对 volatile 变量定义的特殊规则。假定T表示一个线程，V和W分别表示两个volatile 型变量 那么在进行 read, load 和 use assign store  和 write 操作时需要满足如下规则：

* **只有当线程ㄒ对变量执行的前一个动作是 load 的时候，线程才能对变量执行 use 动作；并且，只有当线程ㄒ对变量 v 执行的后一个动作是 use 的时候，线程才能对变量 v 执行 load 动作。线程对变量 V 的 use 动作可以认为是和线程ㄒ对变量 ˇ的 load, read 动作相关联，必须连续一起出现（这条规则要求在工作内存中，每次使用前都必须先从主内存刷新最新的值，用于保证能看见其他线程对变量 v 所做的修改后的值）。**

* **只有当线程对变量 v 执行的前一个动作是 assign 的时候，线程ㄒ才能对变量 v 执行 store 动作；并且，只有当线程对变量执行的后一个动作是 store 的时候，线程ㄒ才能对变量执行 assign 动作。线程对变量 V 的 assign 动作可以认为是和线程对变量的 store, write 动作相关联，必须连续一起出现（这条规则要求在工作内存中，每次修改后都必须立刻同步回主内存中，用于保证其他线程可以看到自己对变量所做的修改）。**

* **假定动作 A 是线程 T 对变量 V 实施的 use 或 assign 动作，假定动作 F 是和动作 A 相关联的 load 或 store 动作，假定动作 P 是和动作 F 相应的对变量 V 的 read 或 write 动作；类似的，假定动作 B 是线程对变量 W 实施的 use 或 assign 动作，假定动作 G 是和动作 B 相关联的 load 或 store 动作，假定动作 Q 是和动作 G 相应的对变量 w 的 read 或 write 动作。如果 A 先于 B，那么 P 先于 Q（这条规则要求 volatile 修饰的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相同）。**

### 5.3.4.对于long和double特殊规则

Java 内存模型要求 lock, unlock. Read. Load. Assign, use. Store. Write 这 8 个操作都具有原子性，但是对于 64 位的数据类型（long 和 double），在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，即允许虚拟机实现选择可以不保证 64 位数据类型的 load, store. Read 和 write 这 4 个操作的原子性，这点就是所谓的 long 和 double 的非原子性协定（NonatomicTreatmentofDoubleandlongVariables).

如果有多个线程共享一个并未声明为 volatile 的 long 或 double 类型的变量,并且同时对如果有多个线程共享一个并未声明为 volatile 的 long 或 double 类型的变量，也不是其他线程修改它们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，值的代表了“半个变量”的数值不过这种读取到“半个变量”的情况非常罕见（在目前商用 Java 虚拟机中不会出现），因为 Java 内存模型虽然允许虚拟机不把 long 和 double 变量的读写实现成原子操作，但允许虚拟机选择把这些操作实现为具有原子性的操作，而且还“强烈建议”虚拟机这样实现在实际开发中，目前各种平台下的商用虚拟机几乎都选择把 64 位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要把用到的 long 和 double 变量专门声明为 volatile

### 5.3.5.原子性/可见性与有序性

原子性（Atomicity）：由 Java 内存模型来直接保证的原子性变量操作包括 read, load assig 和 write，我们大致可以认为基本数据类型的访问读写是具备原子性的（例 nusestore 外就是 long 和 double 的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）。如果应用场景需要一个更大范围的原子性保证（经常会遇到）, Java 内存模型还提供了 lock 和 unlock 操作来满足这种需求，尽管虚拟机未把 lock 和 unlock 操作直接开放给用户使用，但是却提供了更高层次的字节码指令 monitorenter 和 monitorexit 来隐式地使用这两个操作，这两个字节码指令反映到 Java 代码中就是同步块一一synchronized 关键字，因此在 synchronized 块之间的操作也具备原子性。

可见性（Visibility）：可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。上文在讲解 volatile 变量的时候我们已详细讨论过这一点。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是 volatile 变量都是如此，普通变量与 volatile 变量的区别是，volatile 的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此，可以说 volatile 保证了多线程操作时变量的可见性，而普通变量则不能保证这一点.除了 volatile 之外，Java 还有两个关键字能实现可见性，即 synchronized 和 final。同步块的可见性是由“对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中（执行 store、write 操作）”这条规则获得的，而 final 关键字的可见性是指：被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有把this的引用传递出去（this 引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见 final 字段的值。如代码清单 12-7 所示，变量 i 与 j 都具备可见性，它们无须同步就能被其他线程正确访问。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-062537.png)

* 有序性（Ordering): Java 内存模型的有序性在前面讲解 volatile I 时也详细地讨论过了，Java 程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的：如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义”（Within- Thread As-f- Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。
* Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性，volatile 关键字本身就包含了禁止指令重排序的语义，而 synchronized 则是由“一个变量在同一个时刻只允许一条线程对其进行 lock 操作”这条规则获得的，这条规则决定了持有同一个锁的两个同步块只能串行地进入。


### 5.3.6.先发生原则

如果 Java 内存模型中所有的有序性都仅仅靠 volatile 7 和 synchronized 来完成，那么有一些操作将会变得很烦琐，但是我们在编写 Java 并发代码的时候并没有感觉到这一点，这是因为 jJaa 语言中有一个“先行发生”（happens- before）的原则。这个原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地解决并发环境下两个操作之间是否可能存在冲突的所有问题。

现在就来看看“先行发生”原则指的是什么。先行发生是 Java 内存模型中定义的两项操作之间的偏序关系，如果说操作 A 先行发生于操作 B，其实就是说在发生操作 B 之前，操作 A 产生的影响能被操作 B 观察到，“影响”包括修改了内存中共享变量的值、发送了消息谢用了方法等。这句话不难理解，但它意味着什么呢？我们可以举个例子来说明一下，如代码清单 12-8 中所示的这 3 句例代码。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-064005.png)

假设线程 A 中的操作“i=1”先行发生手线程 B 的操作“j=i”，那么可以确定在线程 B 的操作执行后，变量 j 的值一定等于 1, 得出这个结论的依据有两个：一是根据先行发生原则，“=1”的结果可以被观察到；二是线程 C 还没“登场”，线程 A 操作结束之后没有其他线程会修改变量 i 的值。现在再来考虑线程 C，我们依然保持线程 A 和线程 B 之间的先行发生关系，而线程 C 出现在线程 A 和线程 B 的操作之间，但是线程 C 与线程 B 没有先行发生关系，那 j 的值会是多少呢？答案是不确定！1 和 2 都有可能，因为线程 C 对变量 i 的影响可能会被线程 B 观察到，也可能不会，这时候线程 B 就存在读取到过期数据的风险，不具备多线程安全性。

下面是 Java 内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。

* 程序次序规则（ProgramOrderRule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。
* 管程锁定规则（MonitorLockRule）：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序 
* volatile 变量规则（VolatileVariableRule）：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序
* 线程启动规则（ThreadStartRule): Thread 对象的 start（）方法先行发生于此线程的每个动作
* 线程终止规则（ThreadTerminationRule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过 Thread. Join（）方法结束、Thread. IsAlive（）的返回值等手段检测到线程已经终止执行
* 线程中断规则（ThreadinterruptionRule）：对线程 interrupt（）方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread. Interrupted（）方法检测到是否有中断发生
* 对象终结规则（FinalizerRule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize（）方法的开始
* 传递性（Transitivity）：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 c。那就可以得出操作 A 先行发生于操作的结论。

Java 语言无须任何同步手段保障就能成立的先行发生规则就只有上面这些了

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-065824.png)

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-065836.png)

代码清单 12-10 的两条赋值语句在同一个线程之中，根据程序次序规则，"inti=1"的操作先行发生于“intj-2“，但是“intj-2”的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条线程之中没有办法感知到这点上面两个例子综合起来证明了一个结论：**时间先后顺序与先行发生原则之间基本没有太大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发生原则为准**

## 5.4.Java与线程

### 5.4.1.线程的实现

我们知道，线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度夯开，各个线程既可以共享进程资源（内存地址、又可以独文件等），立调度（线程是 CPU 调度的基本单位）。

主流的操作系统都提供了线程实现，Java 语言则提供了在不同硬件和操作系统平台下对线程操作的统一处理，每个已经执行 start（）且还未结束的 java. Lang, Thread 类的实例就代表了一个线程。我们注意到 Thread 类与大部分的 JavaAPI 有显著的差别，它的所有关键方法都是声明为 Native 的。在 JavaAPI 中，一个 Native 方法往往意味着这个方法没有使用或无法使用平台无关的手段来实现（当然也可能是为了执行效率而使用 Native 方法，不过，通常最高效率的手段也就是平台相关的手段），正因为如此，作者把本节的标题定为“线程的实现而不是“Java 线程的实现“.

实现线程主要有 3 种方式：使用内核线程实现、使用用户线程实现和使用用户线程加轻量级进程混合实现。

* 使用内核线程实现

**内核线程（Kernel-LevelThread. KIT）就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（Multi-ThreadsKernel)**程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口--轻量级进程（LightweightProcess, LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间 1:1 的关系称为一对一的线程模型，如图所示。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-072529.png)

由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限性：首先，由于是基于内核线程实现的，所以各种线程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，需要在用户态（UserMode）和内核态（Kernel Mode）中来回切换。其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的

* 使用用户线程实现

从广义上来讲，一个线程只要不是内核线程，就可以认为是用户线程（UserThread. UT），因此，从这个定义上来讲，轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制

而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间的关系称为一对多的线程模型，如图所示

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-073017.png)

使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。因而使用 92 用户线程实现的程序一般都比较复杂，除了以前在不支持多线程的操作系统中（如 DOS）的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java. Ruby 等语言都曾经使用过用户线程，最终又都放弃使用它。

* 使用用户线程加轻量级进程混合实现

线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。在这种混合模式中，用户线程与轻量级进程的数量比是不定的，即为 N: M 的关系，如图 12-5 所示，这种就是多对多的线程模型.

许多 UNIX 系列的操作系统，如 Solaris, HP-UX 等都提供了 N: M 的线程模型实现。

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-073635.png)

* Java线程的实现

Java 线程在 JDK1.2 之前，是基于称为“绿色线程”（GreenThreads）的用户线程实现的，而在 JDK1.2 中，线程模型替换为基于操作系统原生线程模型来实现。因此，在目前的 JDK 版本中，操作系统支持怎样的线程模型，在很大程度上决定了 Java 虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也并未限定 Java 线程需要使用哪种线程模型来实现。线程模型只对线程的并发规模和操作成本产生影响，对 Java 程序的编码和运行过程来说，这些差异都是透明的。

对于 SunJDK 来说，它的 Windows 版与 Linux 版都是使用一对一的线程模型实现的，条 Java 线程就映射到一条轻量级进程之中，因为 Windows 和 Linux 系统提供的线程模型就是一对一的.

而在 Solaris 平台中，由于操作系统的线程特性可以同时支持一对一（通过 Bound ThreadsAlternateLibthread实现)及多对多(通过LWP/ThreadBasedSynchronization 实现）的线程模型，因此在 Solaris 版的 JDK 中也对应提供了两个平台专有的虚拟机参数：-XX: +UseLWPSynchronization（默认值）和-XX: +UseBoundThreads 来明确指定虚拟机使用哪种线程模型。

### 5.4.2.Java线程调度

线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，外别是协同式线程调度（CooperativeThreads-Scheduling）和抢占式线程调度（PreemptiveThreads- Scheduling)

如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。Lua 语言中的“协同例程”就是这类实现。它的坏处也很明显：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。很久以前的 Windows3. X 系统就是使用协同式来实现多进程多任务的，相当不稳定，一个进程坚持不让出 CPU 执行时间就可能会导致整个系统崩溃。

如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定（在 Java 中，Thread·yield（）可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法的），在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java 使用的线程调度方式就是抢占 式调度®,与前面所说的Windows3.x的例子相对,在Windows9 x/NT 内核中就是使用抢占式来实现多进程的，当一个进程出了问题，我们还可以使用任务管理器把这个进程“杀掉“，而不至于导致系统崩溃。

虽然 Java 线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点--这项操作可以通过设置线程优先级来完成。Java 语言一共设置了 10 个级别的线程优先级（Thread. MINPRIORITY 至 Thread. MAXPRIORITY），在两个线程同时处于 Ready 状态时，优先级越高的线程越容易被系统选 - 择执行。

不过，线程优先级并不是太靠谱，原因是 Java 的线程是通过映射到系统的原生线程上来实现的，所以线程调度最终还是取决于操作系统，虽然现在很多操作系统都提供线程优先级的概念，但是并不见得能与 Java 线程的优先级一一对应，如 Solaris 中有 2147483648 (232) 种优先级，但 Windows 中就只有 7 种，比 Java 线程优先级多的系统还好说，中间留下点空位就可以了，但比 Java 线程优先级少的系统，就不得不出现几个优先级相同的情况了，表 12-1 显示了 Java 线程优先级与 Windows 线程优先级之间的对应关系，Windows 平台的 JDK 中使用了除 THREADPRIORITYIDLE 之外的其余 6 种线程优先级

![image](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-081216.png)

上文说到“线程优先级并不是太靠谱”，不仅仅是说在一些平台上不同的优先级实际会变得相同这一点，还有其他情况让我们不能太依赖优先级：优先级可能会被系统自行改变。

如，在 Windows 系统中存在一个称为“优先级推进器“(PriorityBoosting，当然它吸以被。关闭掉）的功能，它的大致作用就是当系统发现一个线程执行得特别 E“勤奋努力”的话，能会越过线程优先级去为它外配执行时间。因此，我们不能在程序中通过优先级来完全准确地判断一组状态都为 Ready 的线程将会先执行哪一个

### 5.4.3.状态转换

Java 语言定义了 5 种线程状态-在任意一个时间点，一个线程只能有且只有其中的一种状态这 5 种状态分别如下。

* 新建（New）: 创建后尚未启动的线程处于这种状态
* 运行（Runable): 包括了操作系统线程状态中的 Running 和 Ready，也就是处于此状态的线能正在执行也有可能正在等待着 CPU 为它分配执行时间。
* 无限期等待（Waiting）：处于这种状态的线程不会被分配CPU执行时间，它们要等待被其他线程显式地唤醒。以下方法会让线程陷大无限期的等待状态。
  * 没有设置 Timeout 参数的 Object.wait()方法
  * 没有设置 Timeout 参数的Thread.join()方法
  * LockSupport.part()方法
* 限期等待（TimedWaiting）：处于这种状态的线程也不会被分配 CPU 执行时间，不过无须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程进人限期等待状态；
  * Thread. Sleep（）方法
  * 设置了 Timeout 参数的 Object. Wait（）方法。
  * 设置了 Timeout 参数的 Thread-join（）方法。
  * LockSupport. ParkNanos（）方法。
  * LockSupport. ParkUntil（）方法。
* 阻塞(Blocked）：线程被阻塞了，“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进人这种状态
* 结束（Terminated）：已终止线程的线程状态，线程已经结束执行。太

![](http://clsaa-big-data-notes-1252032169.cossh.myqcloud.com/2019-03-05-081733.png)

没有设置 Timeout 参数的 Thread"join（）方法。。LockSupportpark（）方法。
