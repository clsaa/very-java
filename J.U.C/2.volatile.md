# volatile

## 1.操作系统语意

计算机在运行程序时，每条指令都是在 CPU 中执行的，在执行过程中势必会涉及到数据的读写。我们知道程序运行的数据是存储在主存中，这时就会有一个问题，读写主存中的数据没有 CPU 中执行指令的速度快，如果任何的交互都需要与主存打交道则会大大影响效率，所以就有了 CPU 高速缓存。CPU高速缓存为某个CPU独有，只与在该CPU运行的线程有关。

有了 CPU 高速缓存虽然解决了效率问题，但是它会带来一个新的问题：数据一致性。在程序运行中，会将运行所需要的数据复制一份到 CPU 高速缓存中，在进行运算时 CPU 不再也主存打交道，而是直接从高速缓存中读写数据，只有当运行结束后，才会将数据刷新到主存中。举一个简单的例子：

```
i = i + 1;
```

当线程运行这段代码时，首先会从主存中读取 i 的值( 假设此时 i = 1 )，然后复制一份到 CPU 高速缓存中，然后 CPU 执行 + 1 的操作（此时 i = 2），然后将数据 i = 2 写入到告诉缓存中，最后刷新到主存中。

其实这样做在单线程中是没有问题的，有问题的是在多线程中。如下：

假如有两个线程 A、B 都执行这个操作（ i++ ），按照我们正常的逻辑思维主存中的i值应该=3 。但事实是这样么？分析如下：

两个线程从主存中读取 i 的值( 假设此时 i = 1 )，到各自的高速缓存中，然后线程 A 执行 +1 操作并将结果写入高速缓存中，最后写入主存中，此时主存 i = 2 。线程B做同样的操作，主存中的 i 仍然 =2 。所以最终结果为 2 并不是 3 。这种现象就是缓存一致性问题。

解决缓存一致性方案有两种：

1. 通过在总线加 LOCK# 锁的方式, 第一种方案， 存在一个问题，它是采用一种独占的方式来实现的，即总线加 LOCK# 锁的话，只能有一个 CPU 能够运行，其他 CPU 都得阻塞，效率较为低下。
2. 通过缓存一致性协议（MESI 协议）, 第二种方案，缓存一致性协议（MESI 协议），它确保每个缓存中使用的共享变量的副本是一致的。其核心思想如下：当某个 CPU 在写数据时，如果发现操作的变量是共享变量，则会通知其他 CPU 告知该变量的缓存行是无效的，因此其他 CPU 在读取该变量时，发现其无效会重新从主存中加载数据。


## 2.Java内存模型

### 2.1.原子性

>原子性：即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

原子性就像数据库里面的事务一样，他们是一个团队，同生共死。其实理解原子性非常简单，我们看下面一个简单的例子即可：

```
i = 0;  // <1>
j = i ;  // <2>
i++;  // <3>
i = j + 1; // <4>
```

上面四个操作，有哪个几个是原子操作，那几个不是？如果不是很理解，可能会认为都是原子性操作，其实只有 1 才是原子操作，其余均不是。


上面四个操作，有哪个几个是原子操作，那几个不是？如果不是很理解，可能会认为都是原子性操作，其实只有 1 才是原子操作，其余均不是。

```
<1>：在 Java 中，对基本数据类型的变量和赋值操作都是原子性操作。
<2>：包含了两个操作：读取 i，将 i 值赋值给 j 。
<3>：包含了三个操作：读取 i 值、i + 1 、将 +1 结果赋值给 i 。
<4>：同 <3> 一样
```

那么 64 位的 JDK 环境下，对 64 位数据的读写是否是原子的呢？

>17.7. Non-Atomic Treatment of double andlongFor the purposes of the Java programming language memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half. This can result in a situation where a thread sees the first 32 bits of a 64-bit value from one write, and the second 32 bits from another write.Writes and reads of volatile long and double values are always atomic.Writes to and reads of references are always atomic, regardless of whether they are implemented as 32-bit or 64-bit values.Some implementations may find it convenient to divide a single write action on a 64-bit long or double value into two write actions on adjacent 32-bit values. For efficiency's sake, this behavior is implementation-specific; an implementation of the Java Virtual Machine is free to perform writes to longand double values atomically or in two parts.Implementations of the Java Virtual Machine are encouraged to avoid splitting 64-bit values where possible. Programmers are encouraged to declare shared 64-bit values as volatile or synchronize their programs correctly to avoid possible complications.

* 实现对普通long与double的读写不要求是原子的（但如果实现为原子操作也OK）
* 实现对volatile long与volatile double的读写必须是原子的（没有选择余地）

在实际开发 中， 目前 各种 平 台下 的 商用 虚拟 机 几乎 都 选择 把 64 位 数据 的 读写 操作 作为 原子 操作 来 对待， 因此 我们 在编 写 代码 时 一般 不需 要把 用到 的 long 和 double 变量 专门 声明 为 volatile。

### 2.2.可见性

>可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

在上面已经分析了，在多线程环境下，一个线程对共享变量的操作对其他线程是不可见的。

Java提供了 volatile 来保证可见性。

当一个变量被 volatile 修饰后，表示着线程本地内存无效。当一个线程修改共享变量后他会立即被更新到主内存中；当其他线程读取共享变量时，它会直接从主内存中读取。

当然，synchronize 和锁都可以保证可见性。

### 2.3.有序性

>有序性：即程序执行的顺序按照代码的先后顺序执行。

在 Java 内存模型中，为了效率是允许编译器和处理器对指令进行重排序，当然重排序它不会影响单线程的运行结果，但是对多线程会有影响。

Java 提供 volatile 来保证一定的有序性。最著名的例子就是单例模式里面的 DCL（双重检查锁）。这里 LZ 就先不阐述了，后续会有专门的文章分享。

## 2.剖析volatile原理

>volatile 可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在 JVM 底层，volatile 是采用“内存屏障”来实现的。

上面那段话，有两层语义：

* 保证可见性、不保证原子性
* 禁止指令重排序

第一层语义就不做介绍了，下面重点介绍指令重排序。

在执行程序时为了提高性能，编译器和处理器通常会对指令做重排序：

* 编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
* 处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

指令重排序对单线程没有什么影响，他不会影响程序的运行结果，但是会影响多线程的正确性。既然指令重排序会影响到多线程执行的正确性，那么我们就需要禁止重排序。那么JVM是如何禁止重排序的呢?

我们着重看第三点 Volatile规则：对 volatile变量的写操作，happen-before 后续的读操作。为了实现 volatile 内存语义，JMM会重排序，其规则如下：

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-13-161725.png)

当第二个操作是 volatile 写操作时，不管第一个操作是什么，都不能重排序。这个规则，确保 volatile 写操作之前的操作，都不会被编译器重排序到 volatile 写操作之后

对 happen-before 原则有了稍微的了解，我们再来回答这个问题 JVM 是如何禁止重排序的？

观察加入 volatile 关键字和没有加入 volatile 关键字时所生成的汇编代码发现，加入volatile 关键字时，会多出一个 lock 前缀指令。lock 前缀指令，其实就相当于一个内存屏障。内存屏障是一组处理指令，用来实现对内存操作的顺序限制。volatile 的底层就是通过内存屏障来实现的。下图是完成上述规则所需要的内存屏障：

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-13-162106.png)

上面的描述仍然不太容易理解，我们还是继续通过一个例子来看看为何指令重排序会干扰程序的并发执行，演示程序如代码清单所示。

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-07-103503.png)

代码清单 12-4 中的程序是一段伪代码，其中描述的场景十分常见，只是我们在处理配置文件时一般不会出现并发而已。如果定义 initialized 变量时没有使用 volatile 修饰，就可能会由于指令重排序的优化，导致位于线程 A 中最后一句的代码“initialized-true'，被提前执行（这里虽然使用 Java 作为伪代码，但所指的重排序优化是机器级的优化操作，提前执行是指这句话对应的汇编代码被提前执行），这样在线程 B 中使用配置信息的代码就可能出现错误，而 volatile 关键字则可以避免此类情况的发生.指令重排序是并发编程中最容易让开发人员产生疑惑的地方，除了上面伪代码的例子之外，笔者再举一个可以实际操作运行的例子来外析 volatile 关键字是如何禁止指令重排序优化的。代码清单是一段标准的 DCL 单例代码，可以观察加入 volatile 和未加入 volatile 关键字时所生成汇编代码的差别

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-07-103505.png)

**Volatile 屏蔽指令重排序的语义在 JDK1.5 中才被完全修复，此前的 JDK 中即使将变量声明为 volatile 也仍然不能完全避免重排序所导致的问题（主要是 volatile 变量前后的代码仍然存在重排序问题），这点也是在 JDK 1.5 之前的 Java 中无法安全地使用 DCL（双锁检测）来实现单例模式的原因**。

通过对比就会发现，关键变化在于有 volatile 修饰的变量，赋值后（前面 mov%eax,)“操作，这个操 0 x150 (%esi）这句便是赋值操作）多执行了一个“lockaddl$0 x0, (%esp作相当于一个内存屏障（MemoryBarrier 或 MemoryFence，指令重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个 CPU 访问内存时，并不需要内存屏障；但如果有两个或更多 CPU 访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证一致性了。这句指令中的“addl$0 x0, (%esp) "（把 ESP 寄存器的值加 0) 显然是一个空操作指令（采用这个空操作而不是空操作指令 nop 是因为 IA32 手册规定 lock 前缀不允许配合 nop 使用），关键在于 lock 前缀，查询 IA32 手册，它的作用是使得本 CPU 的 Cache 写入了内存。该写入动作也会引起别的 CPU 或者别的内核无效化（Invalidate）其 Cache，这种操作相当于对 Cache 中的变量做了一次前面介绍 Java 内存模式中所说的“store 和 write“操作，所以通过这样一个空操作，可让前面 volatile 变量的修改对其他 CPU 立即可见

volatile 暂且下分析到这里，JMM 体系较为庞大，不是三言两语能够说清楚的，后面会结合 JMM 再一次对 volatile 深入分析。

## 3.总结

* volatile 看起来简单，但是要想理解它还是比较难的，这里只是对其进行基本的了解。
* volatile 相对于 synchronized 稍微轻量些，在某些场合它可以替代 synchronized ，但是又不能完全取代 synchronized 。只有在某些场合才能够使用 volatile，使用它必须满足如下两个条件：
  * 对变量的写操作，不依赖当前值。
  * 该变量没有包含在具有其他变量的不变式中。

>volatile 经常用于两个两个场景：状态标记变量、Double Check 。