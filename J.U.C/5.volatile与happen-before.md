# volatile与happen-before

## 1.volatile 与 happens-before

下面我们就那个经典的例子，来分析 volatile 变量的读写，如何建立的 happens-before 关系。

```java
public class VolatileTest {

    int i = 0;
    volatile boolean flag = false;

    // Thread A
    public void write(){
        i = 2;              // 1
        flag = true;        // 2
    }

    // Thread B
    public void read(){
        if(flag) {                                   // 3
            System.out.println("---i = " + i);      // 4
        }
    }
}
```

依据 happens-before 原则，就上面程序得到如下关系：

操作 1、操作 4 存在 happens-before 关系，那么操作 1 一定是对 操作 4 是可见的。可能有同学就会问，操作 1、操作 2 可能会发生重排序啊，会吗？如果看过 LZ 的博客就会明白，volatile 除了保证可见性外，还有就是禁止重排序。所以 A 线程在写 volatile 变量之前所有可见的共享变量，在线程 B 读同一个 volatile 变量后，将立即变得对线程 B 可见。

## 2.volatile的内存语义及其实现

当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量值，立即刷新到主内存中。
当读一个 volatile 变量时，JMM 会把该线程对应的本地内存设置为无效，直接从主内存中读取共享变量

所以 volatile 的写内存语义是直接刷新到主内存中，读的内存语义是直接从主内存中读取。

那么 volatile 的内存语义是如何实现的呢？对于一般的变量则会被重排序，而对于 volatile 的变量则不能。这样会影响其内存语义，所以为了实现 volatile 的内存语义，JMM 会限制重排序。其重排序规则如下：

* 如果第一个操作为 volatile 读，则不管第二个操作是啥，都不能重排序。这个操作确保volatile 读之后的操作，不会被编译器重排序到 volatile 读之前；
* 如果第二个操作为 volatile 写，则不管第一个操作是啥，都不能重排序。这个操作确保volatile 写之前的操作，不会被编译器重排序到 volatile 写之后；
* 当第一个操作 volatile 写，第二个操作为 volatile 读时，不能重排序。

volatile 的底层实现，是通过插入内存屏障。但是对于编译器来说，发现一个最优布置来最小化插入内存屏障的总数几乎是不可能的，所以，JMM 采用了保守策略。

* 在每一个 volatile 写操作前面，插入一个 StoreStore 屏障
* 在每一个 volatile 写操作后面，插入一个 StoreLoad 屏障
* 在每一个 volatile 读操作后面，插入一个 LoadLoad 屏障
* 在每一个 volatile 读操作后面，插入一个 LoadStore 屏障

* StoreStore 屏障：保证在 volatile 写之前，其前面的所有普通写操作，都已经刷新到主内存中。
  * 序列：Store1，StoreStore，Store2
  * 确保Store1的数据在Store2以及后续Store指令操作相关数据之前对其它处理器可见（例如向主存刷新数据）。通常情况下，如果处理器不能保证从写缓冲或/和缓存向其它处理器和主存中按顺序刷新数据，那么它需要使用StoreStore屏障。
* StoreLoad 屏障：避免 volatile 写，与后面可能有的 volatile 读 / 写操作重排序。
  * 序列: Store1; StoreLoad; Load2
  * 确保Store1的数据在被Load2和后续的Load指令读取之前对其他处理器可见。StoreLoad屏障可以防止一个后续的load指令 不正确的使用了Store1的数据，而不是另一个处理器在相同内存位置写入一个新数据。
* LoadLoad 屏障：禁止处理器把上面的 volatile读，与下面的普通读重排序。
  * 序列：Load1,Loadload,Load2
  * 确保Load1所要读入的数据能够在被Load2和后续的load指令访问前读入。通常能执行预加载指令或/和支持乱序处理的处理器中需要显式声明Loadload屏障，因为在这些处理器中正在等待的加载指令能够绕过正在等待存储的指令。 而对于总是能保证处理顺序的处理器上，设置该屏障相当于无操作。
* LoadStore 屏障：禁止处理器把上面的 volatile读，与下面的普通写重排序。
  * 序列： Load1; LoadStore; Store2
  * 确保Load1的数据在Store2和后续Store指令被刷新之前读取。在等待Store指令可以越过loads指令的乱序处理器上需要使用LoadStore屏障。

### 2.1.案例 1：VolatileTest

```java
public class VolatileTest {
    
    int i = 0;
    volatile boolean flag = false;
    
    public void write() {
        i = 2;
        flag = true;
    }

    public void read() {
        if (flag){
            System.out.println("---i = " + i);
        }
    }
    
}
```

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-14-061330.png)

### 2.2.案例 2：VolatileBarrierExample

volatile 的内存屏障插入策略非常保守，其实在实际中，只要不改变 volatile 写-读的内存语义，编译器可以根据具体情况优化，省略不必要的屏障。如下例子，摘自方腾飞 《Java并发编程的艺术》：

```java
public class VolatileBarrierExample {
    int a = 0;
    volatile int v1 = 1;
    volatile int v2 = 2;

    void readAndWrite(){
        int i = v1;     //volatile读
        int j = v2;     //volatile读
        a = i + j;      //普通读
        v1 = i + 1;     //volatile写
        v2 = j * 2;     //volatile写
    }
}
```

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-14-062316.png)

我们来分析，上图有哪些内存屏障指令是多余的：

1：这个肯定要保留了
2：禁止下面所有的普通写与上面的 volatile 读重排序，但是由于存在第二个 volatile读，那个普通的读根本无法越过第二个 volatile 读。所以可以省略。
3：下面已经不存在普通读了，可以省略。
4：保留
5：保留
6：下面跟着一个 volatile 写，所以可以省略
7：保留
8：保留

所以 2、3、6 可以省略，其示意图如下：

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-14-062608.png)

![image](https://clsaa-markdown-imgbed-1252032169.cos.ap-shanghai.myqcloud.com/very-java/2019-03-14-062629.png)